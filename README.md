# Models

Put your models in ./models. Currently testing with Llama3.

If using huggingface CLI, just do the following:

```bash
cd models

huggingface-cli download QuantFactory/Meta-Llama-3-8B-Instruct-GGUF Meta-Llama-3-8B-Instruct.Q2_K.gguf --local-dir . --local-dir-use-symlinks False
```
